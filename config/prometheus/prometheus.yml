global:
  # This is the Prometheus default already, but lets be explicit about it.
  scrape_interval: 1m

alerting:
  alertmanagers:
    - path_prefix: "alertmanager/"
      static_configs:
        - targets: ['alertmanager:9093']

scrape_configs:
  - job_name: 'prometheus'
    # This needs to match the web.external-url flag we use to run prometheus.
    metrics_path: /prometheus/metrics
    static_configs:
      - targets: ['127.0.0.1:9090']

  - job_name: 'alertmanager'
    metrics_path: /alertmanager/metrics
    static_configs:
      - targets: ['alertmanager:9093']

  - job_name: 'grafana'
    metrics_path: /grafana/metrics
    static_configs:
      - targets: ['grafana:3000']

  - job_name: 'proxy-metrics'
    static_configs:
      - targets: ['montagu.vaccineimpact.org:9113', 'uat.montagu.dide.ic.ac.uk:9113', 'science.montagu.dide.ic.ac.uk:9113']
    relabel_configs:
      - source_labels: [__address__]
        target_label: instance
        regex: (uat)(.+)(9113)
        replacement: 'UAT'
      - source_labels: [__address__]
        target_label: instance
        regex: (science)(.+)(9113)
        replacement: 'Science'
      - source_labels: [__address__]
        target_label: instance
        regex: (.+)(vaccineimpact)(.+)
        replacement: 'Production'

  - job_name: 'orderly-web'
    metrics_path: /reports/metrics
    scheme: https
    static_configs:
      - targets: ['montagu.vaccineimpact.org', 'science.montagu.dide.ic.ac.uk']
        labels:
          frequency: high
      - targets: ['uat.montagu.dide.ic.ac.uk']
        labels:
          frequency: low
    relabel_configs:
      - source_labels: [__address__]
        target_label: instance
        regex: (uat)(.+)
        replacement: 'UAT'
      - source_labels: [__address__]
        target_label: instance
        regex: (science)(.+)
        replacement: 'Science'
      - source_labels: [__address__]
        target_label: instance
        regex: (.+)(vaccineimpact)(.+)
        replacement: 'Production'

  - job_name: 'hint'
    scheme: https
    static_configs:
      - targets: ['naomi.unaids.org']
        labels:
          project: hint
          frequency: high

  - job_name: 'hint-preview'
    scheme: https
    static_configs:
      - targets: ['naomi-preview.dide.ic.ac.uk']
        labels:
          project: hint

  - job_name: 'buildkite-metrics'
    static_configs:
    - targets: ['buildkite_metrics:8080']

  - job_name: 'machine-metrics'
    static_configs:
    - targets: ['naomi.dide.ic.ac.uk:9100']
      labels:
        project: hint
        frequency: high
        instance: 'hint production'
    - targets: ['wpia-naomi-preview.dide.ic.ac.uk:9100']
      labels:
        project: hint
        instance: 'hint preview'
    - targets: ['montagu.vaccineimpact.org:9100']
      labels:
        instance: 'montagu production'
    - targets: ['wpia-annex2.montagu.dide.ic.ac.uk:9100']
      labels:
        instance: 'montagu annex'
    - targets:
      - wpia-gpu-01.dide.ic.ac.uk:9100
      - wpia-gpu-02.dide.ic.ac.uk:9100
    relabel_configs:
      # Override the default instance name to remove the port
      - source_labels: [__address__]
        regex: (.+):(.+)
        target_label: instance
        replacement: $1

  - job_name: 'machine-metrics-buildkite'
    file_sd_configs:
      - files: [ /etc/prometheus/generated/buildkite-nodes.json ]
    relabel_configs:
      - source_labels: [__address__]
        replacement: $0:9100
        target_label: __address__
      - target_label: job
        replacement: "machine-metrics"

  - job_name: 'DCGM'
    static_configs:
    - targets:
      # DCGM-exporter is only running on GPU-01 for now because GPU-02 is
      # running an older Ubuntu version where it isn't packaged.
      - wpia-gpu-01.dide.ic.ac.uk:9400
    relabel_configs:
      # Override the default instance name to remove the port
      - source_labels: [__address__]
        regex: (.+):(.+)
        target_label: instance
        replacement: $1

  # The packit servers have a whole slew of services we want to scrape. To ease
  # configuration, each server exposes a JSON document that lists them all.
  # Prometheus dynamically discovers the services to scrape by fetching that
  # endpoint.
  - job_name: 'packit'
    http_sd_configs:
      - url: "http://packit.dide.ic.ac.uk:9000/targets"
      - url: "http://packit-dev.dide.ic.ac.uk:9000/targets"
      - url: "http://packit-private.dide.ic.ac.uk:9000/targets"
    relabel_configs:
      # Override the default instance name to remove the port
      - source_labels: [__address__]
        regex: (.+):(.+)
        target_label: instance
        replacement: $1

  # We run a couple of "multi-target exporters", that expose a different service
  # as prometheus metrics. This scrape job collects the exporters' own metrics.
  - job_name: 'exporter'
    metrics_path: /metrics
    static_configs:
      - targets:
          - blackbox-exporter:9115
          - redis-exporter:9121
          - github-exporter:8080

  - job_name: 'redis'
    static_configs:
      - targets: ['redis://wpia-hn.hpc.dide.ic.ac.uk']
    metrics_path: /scrape

    # See https://github.com/oliver006/redis_exporter/blob/master/README.md#prometheus-configuration-to-scrape-multiple-redis-hosts
    # This rewrites the metrics URL as redis-exporter:9115/scrape?target=<...>
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
        regex: .+://(.+)
        replacement: $1
      - target_label: __address__
        replacement: redis-exporter:9121

  - job_name: 'blackbox-http'
    metrics_path: /probe
    params:
      module: [http_2xx]
    file_sd_configs:
      - files: [ /etc/prometheus/blackbox-probes.yaml ]

    # See https://github.com/prometheus/blackbox_exporter/blob/master/README.md#prometheus-configuration
    # This rewrites the metrics URL as blackbox:9115?target=https://foo.dide.ic.ac.uk
    relabel_configs:
      - source_labels: [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
        regex: ^(.*://)?(.*?)(:\d+)?$
        replacement: $2
      - target_label: __address__
        replacement: blackbox-exporter:9115

  - job_name: 'github'

    # We don't particular care about being very up-to-date, so we reduce the
    # scraping rate to avoid wasting GitHub rate limit credit. We don't want to
    # go over 5 minutes though or Prometheus consideres the data to be stale:
    # https://prometheus.io/docs/prometheus/latest/querying/basics/#staleness
    scrape_interval: 3m
    metrics_path: /scrape
    static_configs:
      - targets: ['reside-ic/packit-infra']
    relabel_configs:
      # This rewrites the metrics URL as github-exporter:8080/scrape?owner=foo&repo=bar
      - source_labels: [__address__]
        target_label: __param_owner
        regex: ^(.*)/(.*)$
        replacement: $1
      - source_labels: [__address__]
        target_label: __param_repo
        regex: ^(.*)/(.*)$
        replacement: $2
      - target_label: __address__
        replacement: github-exporter:8080

  - job_name: 'windows-exporter'
    file_sd_configs:
      - files: [ /etc/prometheus/generated/hpc-windows-nodes.json ]
    relabel_configs:
      # The HPC nodes sit behind a NAT, meaning we can't pull directly from
      # them. The headnode runs a simple reverse-proxy that we connect to, and
      # use `/metrics/<ip>` where `<ip>` represents the actual target we want
      # to reach.
      - source_labels: [__address__]
        replacement: /metrics/$0
        target_label: __metrics_path__
      - target_label: __address__
        replacement: wpia-hn.hpc.dide.ic.ac.uk:9183

rule_files:
  - alert-rules.yml
